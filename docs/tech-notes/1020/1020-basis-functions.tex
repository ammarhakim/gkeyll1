\documentclass[11pt, reqno]{amsart}
\usepackage{hyperref}
%% AMS packages and font files
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage[dvips]{graphicx}
\usepackage[usenames,dvipsnames]{color}
\usepackage{setspace}
\usepackage{fancyhdr}
% \pagestyle{fancyplain}

\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

%% Set page size properly
% \oddsidemargin  0.0in
% \evensidemargin 0.0in
% \textwidth      6.5in
% \textheight     9.0in
% \leftmargin     1.0in
% \rightmargin    1.0in

%% Autoscaled figures
\newcommand{\incfig}{\centering\includegraphics}
\setkeys{Gin}{width=0.9\linewidth,keepaspectratio}

%% Commonly used macros
\newcommand{\eqr}[1]{Eq.\thinspace(#1)}
\newcommand{\pfrac}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pfracc}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\pfraca}[1]{\frac{\partial}{\partial #1}}
\newcommand{\pfracb}[2]{\partial #1/\partial #2}
\newcommand{\pfracbb}[2]{\partial^2 #1/\partial #2^2}
\newcommand{\spfrac}[2]{{\partial_{#1}} {#2}}
\newcommand{\mvec}[1]{\mathbf{#1}}
\newcommand{\gvec}[1]{\boldsymbol{#1}}
\newcommand{\script}[1]{\mathpzc{#1}}
\newcommand{\eep}{\mvec{e}_\phi}
\newcommand{\eer}{\mvec{e}_r}
\newcommand{\eez}{\mvec{e}_z}
\newcommand{\iprod}[2]{\langle{#1}\rangle_{#2}}

\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{example}{Example}

\theoremstyle{definition}
\newtheorem{dfn}{Definition}

\title[Basis Functions]{Basis Functions for use in discontinuous Galerkin schemes}
\author{Ammar H. Hakim}%
\date{}%

\begin{document}
% header text
\lhead{Tech-Note 1020}%
\maketitle

In this document I outline the discontinuous Galerkin (DG) scheme in
the form implemented it in Gkeyll with emphasis on the basis functions
needed. Although the analytical form of the basis functions need to be
developed, they are not explicitly required in the code
itself. Instead, various matrices and mappings computed from the basis
function are needed in the DG and the continuous Galerkin (CG)
updaters. These are defined and listed in this document.

\section{Basic formulation of discontinuous Galerkin scheme}

The DG scheme in Gkeyll is designed to solve the following set of
hyperbolic partial differential equations
\begin{align}
  \pfrac{f}{t} + \nabla\cdot\mvec{g} = 0 \label{eq:cons-law}
\end{align}
where $f(\mvec{x},t)$ is a vector of conserved variables and $\mvec{g}
= \mvec{g}(f(\mvec{x},t))$ are the \emph{flux-functions}. In
particular, we are interested in the case in which the conserved
variable is a scalar (the particle distribution function) and the
fluxes are written as phase-space divergence with characteristics
computed from a Hamiltonian.

Instead of the differential form of the balance law it is
mathematically more appropriate to work with the \emph{weak-form} of
the equations. To derive the weak-form, multiply
\eqr{\ref{eq:cons-law}} by a smooth test function $\varphi(\mvec{x})$
and integrate over an arbitrary region $\Omega$
\begin{align}
  \int_\Omega \varphi \pfrac{f}{t}\thinspace d\mvec{x} 
  + \int_{\partial \Omega}\varphi \mvec{n}\cdot\mvec{g}\thinspace d\mvec{s} 
  - \int_\Omega \nabla\varphi\cdot\mvec{g}\thinspace d\mvec{x}
  = 0
\end{align}
Here $\mvec{n}$ is an outward pointing unit normal on the surface
$\partial\Omega$ that bounds the region $\Omega$. If this equation is
satisfied for all smooth functions $\varphi(\mvec{x})$ then
$f(\mvec{x},t)$ is the solution we are seeking. Note that the
weak-form is \emph{not}, in general, mathematically equivalent to the
differential form; it imposes weaker continuity requirements on the
conserved variables, thus allowing for a broader class of solutions
than does the differential form.

To derive the DG scheme we start with a \emph{triangulation} of the
domain $\Omega$ into non-overlapping cells $\Omega_\mu$,
$\mu=1,\ldots,N_c$, where $N_c$ is the number of cells. Then, letting
$\varphi_j$ be a test function we get the \emph{discrete} weak-form
\begin{align}
  \int_{\Omega_\mu} \varphi_j \pfrac{f}{t}\thinspace d\mvec{x} +
  \int_{\partial \Omega_\mu}\varphi_j^-
  \mvec{n}\cdot\hat{\mvec{g}}\thinspace d\mvec{s} - \int_{\Omega_\mu}
  \nabla\varphi_j\cdot\mvec{g}\thinspace d\mvec{x} = 0.
\end{align}
Here $\varphi_j^-$ indicates that the test function must be evaluated
just inside the surface $\partial \Omega_\mu$. Here $\hat{\mvec{g}} =
\hat{\mvec{g}}(\mvec{g}^+,\mvec{g}^-)$ is a \emph{numerical
  flux-function} that depends on the fluxes computed just outside
($\mvec{g}^+$) and just inside ($\mvec{g}^-$) the surface $\partial
\Omega_\mu$.  For present we will leave the numerical flux-function
unspecified, besides stating that it couples neighboring cells
together and plays a very important role in the scheme. As we have
performed a discretization, the test functions can no longer be
arbitrary smooth functions but instead must lie in some
finite-dimensional function space. This space is usually selected to
be some polynomial space on $\Omega_\mu$ but non-polynomial spaces can
also be used.

Although this is the form of DG implemented in Gkeyll often an
additional integration by parts is performed to derive the following
\emph{strong-form} of the discrete equations\footnote{The name
  strong-form seems very strange and, to my mind,
  unfortunate. However, it is made popular with the nodal DG textbook
  by Hesthaven and Warburton.}
\begin{align}
  \int_{\Omega_\mu} \varphi_j \pfrac{f}{t}\thinspace d\mvec{x} +
  \int_{\partial \Omega_\mu}\varphi_j^- 
  (\mvec{n}\cdot\hat{\mvec{g}}-\mvec{n}\cdot\mvec{g}^-)\thinspace
  d\mvec{s} 
  + \int_{\Omega_\mu} \varphi_j\nabla\cdot\mvec{g}\thinspace
  d\mvec{x} = 0.  
\end{align}
The subtle point in performing the second integration by parts is that
the resulting surface integral must be performed \emph{just inside}
the surface $\partial\Omega_\mu$, leading to the $\mvec{g}^-$
term. Also notice that the derivative in the last term has now been
moved back to the flux-function. This does not impose any additional
constraints as we have assumed that the solution is continuous inside
the cell $\Omega_j$, making this derivative well defined\footnote{I am
  not fully convinced of this. If there is a discontinuity that passes
  through a cell then the derivative can not be computed. But perhaps
  I do not understand why Hesthaven and Warburton do the second
  integration by parts in the first place.}.

The next step is to expand the conserved variables in a cell in some
\emph{basis functions}. Usually, the test functions themselves are
used as basis functions, allowing to write
\begin{align}
  f(\mvec{x},t) = \sum_k f_k(t)
  \varphi_k(\mvec{x}) \label{eq:expansion}.
\end{align}
the summation taken over all the linearly independent functions. Using
this in the discrete weak-form gives
\begin{align}
  \sum_k \int_{\Omega_\mu} \varphi_j\varphi_k \thinspace d\mvec{x}
  \thinspace
  \frac{df_k}{dt} + \int_{\partial \Omega_\mu}\varphi_j^-
  \mvec{n}\cdot\hat{\mvec{g}}\thinspace d\mvec{s} 
  -
  \int_{\Omega_\mu}
  \nabla\varphi_j\cdot\mvec{g}\thinspace d\mvec{x} 
  = 0. \label{eq:dg}
\end{align}
This is the form of the equations implemented in Gkeyll. The code
evolves the coefficients $f_k(t)$ that appear in this equation. Once
these are known the solution inside each cell can be reconstructed
using the expansion \eqr{\ref{eq:expansion}}.

\section{Basis functions and quadrature schemes}

\subsection{Constructing basis functions on a reference cell}

In the above outline of the DG scheme we have not yet specified the
\emph{shape} of the cells $\Omega_\mu$. The DG scheme, like other
finite-element schemes, allows use of any shaped cells. However,
usually simplical (triangles, tetrahedra) or brick (quadrilaterals,
hexahedra) shaped cells are used. In Gkeyll, for the present, we use
bricks. Once the cell shape is selected the DG scheme requires
selecting an appropriate set of basis functions on these
cells. Usually polynomial spaces are selected.  Note that for cells
other than simplexes or bricks, the creation of polynomial spaces on
arbitrary shaped cells is not a completely solved problem.

Instead of designing basis functions for non-rectangular bricks it is
conventional to work with the \emph{reference cell} $I_d$, where $d$
is the dimension of the space, defined as the tensor product of the
interval $I_1 \equiv [-1,1]$. Hence, the reference cell is a
n-dimensional cube centered at the origin with edges of length 2. Once
the basis functions are constructed for the reference element, a
coordinate transformation is used to map them to the actual cell
$\Omega_\mu$. Note that each cell will have a \emph{different} mapping
depending on its shape.

There are two types of basis functions one can design: \emph{modal}
and \emph{nodal} basis functions. In Gkeyll we use nodal basis
functions, although it is possible that we might end up using mixed
nodal-modal basis functions in the future. To design nodal basis
functions, $\psi_k(\mvec{y})$, where $\mvec{y} = (y^1,\ldots,y^d)\in
I_d$ and $k=1,\ldots,N$, we need two ingredients: first, a set of $N$
linearly independent polynomials (or monomials), $v_k(\mvec{y})$,
$k=1,\ldots,N$, that form a basis for the space we wish to
use. Second, a set of $N$ nodes $\mvec{y}_i$, $i=1,\ldots,N$, inside
and, optionally, on the faces of the reference cell $I_d$ such that
\begin{align}
  \psi_k(\mvec{y}_j) = \delta_{kj}, \label{eq:basis-def}
\end{align}
for $k,j=1,\ldots,N$. That is, the $\psi_k$ nodal basis function is
constructed such that is evaluates to unity at node $k$ and vanishes
at all other nodes. The selected set of functions $v_k$ are used to
express the unknown $\psi_k$ as
\begin{align}
  \psi_j(\mvec{y}) = \sum_k \psi^{(k)}_j v_k(\mvec{y})
\end{align}
where $\psi^{(k)}_j$ are unknown coefficients. Using this expansion in
\eqr{\ref{eq:basis-def}} leads to a set of N linear equations for the
coefficients $\psi^{(k)}_j$, $k=1,\ldots,N$, which can be inverted to
obtain an explicit expression for the nodal basis function
$\psi_j(\mvec{y})$.

It is clear than one can not use any arbitrary nodal layout: the
resulting linear system for the expansion coefficients must be
invertible. This requirement is called \emph{unisolvency}. There is
also a more subtle constraint that comes about from the requirement of
using the nodes on a face to construct a complete set of basis
functions on that face. For now, this discussion is differed.

\subsection{Mapping to physical cell}

Once the basis functions on the reference cell are constructed a
mapping is used to transform them to the physical cell. Let $\mvec{x}
= (x^1,\ldots,x^d)$ be the global Cartesian coordinate system spanning
the domain $\Omega$. Then, a mapping $I_d\rightarrow \Omega_\mu$ can
be constructed by specifying
\begin{align}
  x^i = x^i(\mvec{y}).
\end{align}
One option is to use a linear combination of the reference element
basis functions (or a subset) themselves to contruct the required
mapping. This means that the transformations are expressed as
\begin{align}
  x^i(\mvec{y}) = \sum_k x^i_{(k)} \psi_k(\mvec{y})
\end{align}
where $x^i_{(k)}$ are unknown coefficients. To detemine these we can
use, for example, for the cell $\Omega_\mu$ the coordinates of each of
its vertices\footnote{I am distinguishing between \emph{vertices}
  which are used to define a cell $\Omega_\mu$ and \emph{nodes} used
  in the nodal DG scheme. It is possible that some DG nodes might
  coincide with the vertices, but this need not be always true.},
which are presumably known from the output of a mesh
generator\footnote{The point is that the mesh must be generated
  beforehand and that each cell in the mesh must have its vertices
  known. This is the common output from most mesh generators. However,
  it might be advantageous for the problems we are interested in to
  have a special mesh generator that also generates the DG nodes in
  each cell. This might ensure, for example, that the cell edges are
  aligned with the background magnetic field or the surface or a
  curved boundary. In general, however, this will lead to the use of
  cells with curved faces which could complicate the evaluation of
  surface integrals in the DG scheme.}.

\subsection{Quadrature schemes}

Once a coordinate mapping is constructed we can now rewrite volume
integral of a function $h(\mvec{x})$ 
\begin{align}
  \int_{\Omega_\mu}h(\mvec{x})\thinspace d\mvec{x} 
  =
  \int_{I_d}
  h(\mvec{x}(\mvec{y})) J(\mvec{y}) \thinspace d\mvec{y}
\end{align}
where $J(\mvec{y}) \equiv \partial (x^1,\ldots,x^d)/\partial
(y^1,\ldots,y^d)$ is the Jacobian of the transformation. To evaluate
this integral a Gaussian quadrature is used
\begin{align}
  \int_{\Omega_\mu}
  h(\mvec{x})\thinspace d\mvec{x} 
  =
  \int_{I_d}
  h(\mvec{x}(\mvec{y})) J(\mvec{y}) \thinspace d\mvec{y}
  =
  \sum_{i=1}^{N_g} w_ih(\mvec{x}(\mvec{y}_i)) J(\mvec{y}_i)
\end{align}
where $\mvec{y}_i$, $i=1,\ldots,N_g$ are \emph{ordinates} for the
quadrature and $w_i$ are the corresponding \emph{weights}. Notice that
the equality sign and not the approximation sign is used in the last
piece of the above expression. The point being that the quadrature
must be designed such that for cell $\Omega_\mu$ the polynomial space
spanned by the basis functions is integrated \emph{exactly}.

\end{document}

\footnote{I am not sure if the property that in 1D Gaussian
  quadrature with $N_g$ nodes can integrate polynomials with degree at
  most $2N_g-1$ exactly can be preserved under the cordinate
  mapping. This perhaps is true only if the transformation is
  (multi)linear.}

 The basis
functions themselves, or some subset, can be used to construct the
coordinate mappings.

Once the nodal basis functions are determined we can go about
computing the various matrices needed in Gkeyll.
