\documentclass[11pt, reqno]{amsart}
%% AMS packages and font files
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[dvips]{graphicx}
\usepackage[usenames,dvipsnames]{color}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algorithmic}
% \pagestyle{fancyplain}

\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

%% Set page size properly
\oddsidemargin  0.0in
\evensidemargin 0.0in
\textwidth      6.5in
\textheight     9.0in
\headheight     1.0in
%\headsep        0.0in
\leftmargin      1.0in
\rightmargin      1.0in
\topmargin      -.75in

%% Autoscaled figures
\newcommand{\incfig}{\centering\includegraphics}
\setkeys{Gin}{width=0.9\linewidth,keepaspectratio}

%% Commonly used macros
\newcommand{\eqr}[1]{Eq.\thinspace(#1)}
\newcommand{\pfrac}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pfracc}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\pfraca}[1]{\frac{\partial}{\partial #1}}
\newcommand{\pfracb}[2]{\partial #1/\partial #2}
\newcommand{\pfracbb}[2]{\partial^2 #1/\partial #2^2}
\newcommand{\spfrac}[2]{{\partial_{#1}} {#2}}
\newcommand{\mvec}[1]{\mathbf{#1}}
\newcommand{\gvec}[1]{\boldsymbol{#1}}
\newcommand{\script}[1]{\mathpzc{#1}}

\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}

\theoremstyle{definition}
\newtheorem{dfn}{Definition}

\title{Notation and algorithms for coupled simulations}%
\author{Ammar H. Hakim}%
\date{}

\begin{document}
% header text
\lhead{Tech-Note 1001}
\maketitle

\section{The statement of the coupled problem}

Consider the problem of performing multiphysics simulations of complex
systems by coupling existing solvers. The problem can be stated
schematically as solving a coupled system of equations
\begin{align}
  \pfrac{\mvec{U}_1}{t} &= \frac{1}{\varepsilon_1}
  \script{L}_1(\mvec{U}_1, \mvec{c}_2) \label{eq:sys_1} \\
  \pfrac{\mvec{U}_2}{t} &= \frac{1}{\varepsilon_2}
  \script{L}_2(\mvec{U}_2, \mvec{c}_1) \label{eq:sys_2}
\end{align}
where $\mvec{U}_1 \in \mathbb{R}^{m_1}$ and $\mvec{U}_2 \in
\mathbb{R}^{m_2}$ are unknowns, $\mvec{c}_1 \in \mathbb{R}^{n_1}$ and
$\mvec{c}_2 \in \mathbb{R}^{n_2}$ are ``coupling'' variables and
$\varepsilon_1$ and $\varepsilon_2$ are positive scalar parameters. In
general $n_1\le m_1$ and $n_2\le m_2$. The operators $\script{L}_1$
and $\script{L}_2$ represent the physics of the systems being coupled
and may contain spatial derivative terms. The parameters
$\varepsilon_1$ and $\varepsilon_2$ are introduced to study the effect
of different time scales on the coupling. For example, coupling of
physics that occurs on different time scales can be studied by picking
$\varepsilon_1 \ll \varepsilon_2$.

The coupling between \eqr{\ref{eq:sys_1}} and \eqr{\ref{eq:sys_2}} is
through the variables $\mvec{c}_1$ and $\mvec{c}_2$
\begin{align}
  \mvec{c}_1 &= \script{C}_1(\mvec{U}_1) \label{eq:cpl_1} \\
  \mvec{c}_2 &= \script{C}_2(\mvec{U}_2). \label{eq:cpl_2}
\end{align}
The coupled problem can now be stated as follow. Given initial
conditions $\mvec{U}_1(t=0)$ and $\mvec{U}_2(t=0)$ evolve the system
\eqr{\ref{eq:sys_1}} and \eqr{\ref{eq:sys_2}} subject to the coupling
condition \eqr{\ref{eq:cpl_1}} and \eqr{\ref{eq:cpl_2}}.

\section{Explict and implicit coupling}

To solve the coupled problem we will use the following scheme
\begin{align}
  \mvec{U}_1^{n+1} &= \mvec{U}_1^{n} + \frac{\Delta t}{\varepsilon_1}
  \script{L}_1(\mvec{U}_1^{n+1}, \mvec{c}_2^{n+k}) \\
  \mvec{U}_2^{n+1} &= \mvec{U}_2^{n} + \frac{\Delta t}{\varepsilon_2}
  \script{L}_2(\mvec{U}_2^{n+1}, \mvec{c}_1^{n+k})
\end{align}
where
\begin{align}
  \mvec{c}_1^{n+k} &= \script{C}_1(\mvec{U}_1^{n+k}) \\
  \mvec{c}_2^{n+k} &= \script{C}_2(\mvec{U}_2^{n+k})
\end{align}
where $0 \le k \le 1$ and $\mvec{U}_i^k \equiv
(1-k)\mvec{U}_i^n+k\mvec{U}_i^{n+1}$. The coupling is \emph{explicit}
if $k=0$ and \emph{implicit} if $k>0$, in particular, if $k=1$. Here,
we are assuming that each individual system can be solved with an
implicit algorithm with a backward Euler time-discretization.

\section{A closer look at the implicit coupling problem}

For now we will assume that we are interested in the implicit coupling
problem with $k=1$. Also, we will assume that there are available
solvers that given the solution at some time $t_n$ are able to compute
the solution at $t_{n+1} = t_n+\Delta t$
\begin{align}
  \mvec{U}_1^{n+1} &= \script{H}_1(\mvec{U}_1^n, \mvec{c}_2) \\
  \mvec{U}_2^{n+1} &= \script{H}_2(\mvec{U}_2^n, \mvec{c}_1)
\end{align}
Note that the solvers $\script{H}_i$, $i=1,2$ are for the
\emph{uncoupled problem with given} $\mvec{c}_i$. We can regard these
as ``black box'' functions that evolve the individual physics in the
absence of the coupling.

The simplest implicit algorithm is essentially a fixed-point iteration
or \emph{Picard iteration} scheme defined as follows. This algorithm
produces $\mvec{U}_i^{n+1}$ given $\mvec{U}_i^{n}$ and the functions
$\script{H}_i$, for $i=1,2$. The $\mvec{c}_i$ are computed using
\eqr{\ref{eq:cpl_1}} and \eqr{\ref{eq:cpl_2}} and $\epsilon$ is a
small parameter.
\begin{algorithm}
\caption{Coupling with Picard Iteration}
\begin{algorithmic}
%\caption{Coupling with Picard Iteration}
\STATE $\mvec{c}_1^0 \leftarrow \script{C}_1(\mvec{U}_1^n)$
\STATE $\mvec{c}_2^0 \leftarrow \script{C}_2(\mvec{U}_2^n)$
\WHILE{$|\mvec{c}_1^{m+1}-\mvec{c}_1^m| > \epsilon$ and $|\mvec{c}_2^{m+1}-\mvec{c}_2^m| > \epsilon$}
\STATE $\mvec{U}_1^{m+1} = \script{H}_1(\mvec{U}_1^n, \mvec{c}_2^m)$
\STATE $\mvec{U}_2^{m+1} = \script{H}_2(\mvec{U}_2^n, \mvec{c}_1^m)$
\STATE $m \leftarrow m+1$
\ENDWHILE
\end{algorithmic}
\end{algorithm}

Several variations on the Picard iteration can be imagined. For
example the following algorithm uses the updated solution to
$\mvec{U}_1$ to compute the solution $\mvec{U}_2$.
\begin{algorithm}
\caption{Modified Picard Iteration}
\begin{algorithmic}
%\caption{Coupling with Picard Iteration}
\STATE $\mvec{c}_1^0 \leftarrow \script{C}_1(\mvec{U}_1^n)$
\STATE $\mvec{c}_2^0 \leftarrow \script{C}_2(\mvec{U}_2^n)$
\WHILE{$|\mvec{c}_1^{m+1}-\mvec{c}_1^m| > \epsilon$ and $|\mvec{c}_2^{m+1}-\mvec{c}_2^m| > \epsilon$}
\STATE $\mvec{U}_1^{m+1} = \script{H}_1(\mvec{U}_1^n, \mvec{c}_2^m)$
\STATE $\mvec{U}_2^{m+1} = \script{H}_2(\mvec{U}_2^n, \mvec{c}_1^{m+1})$
\STATE $m \leftarrow m+1$
\ENDWHILE
\end{algorithmic}
\end{algorithm}
The disadvantage of this modified algorithm is that it does not allow
concurrent evaluation of the functions $\script{H}_i$ as we need
$\mvec{U}_1^{m+1}$ before $\mvec{U}_2^{m+1}$ can be computed.

\end{document}

For multi-physics, multi-domain simulations one needs to couple
solvers implicitly. Each solver provides the other with a set of
coupling variables which need be made consistent at each
time-step. The problem can be treated as coupling two ``black box''
solvers, i.e. without concern to how the coupling variables are
produced.

In the first section we first treat the problem of coupling
multi-physics, multi-domain solvers using coupling variables. In the
second section we treat the solution of transport equations as a
coupling problem. In this the finite-difference updater is treated as
one solver while the flux calculator is treaed as the second solver.

\section{Coupling multi-physics, multi-domain solvers}

Consider a solver denoted schematically as $\script{C}$ which takes as
input a vector of $N$ variables, $\mvec{c}$, and produces as output a
vector of $M$ variables, $\mvec{e}$, i.e. $\script{C} : R^{N} \mapsto
R^{M}$ and
\begin{align}
  \mvec{e} = \script{C}(\mvec{c}).
\end{align}
Now consider another solver denoted by $\script{E}$ such that
$\script{E} : R^{M} \mapsto R^{N}$ and
\begin{align}
  \mvec{c} = \script{E}(\mvec{e}).
\end{align}
The problem of coupling now can be abstractly stated as determining
the state vector $\mvec{V} \equiv [\mvec{e}, \mvec{c}]^T$ such that
the relation
\begin{align}
  \mvec{e} &= \script{C}(\mvec{c}) \\
  \mvec{c} &= \script{E}(\mvec{e})
\end{align}
holds. This problem can be restated as solving the non-linear system
of algebraic equations 
\begin{align}
  \mvec{G}(\mvec{V}) = \mvec{0}
\end{align}
where $G_i \equiv e_i - \script{C}_i(\mvec{c})$ for $i=1,\ldots,M$ and
$G_{i+M} \equiv c_i - \script{E}_i(\mvec{e})$ for $i=1,\ldots,N$.


\section{One-dimensional Transport Solver as a Coupling Problem}

Consider the one-dimensional transport equation written in the form
\begin{align}
  \pfrac{Q}{t} + \frac{1}{V'} \pfraca{x} \left( V' \Gamma \right) = S
\end{align}
where $Q = Q(x,t)$ is an unknown quantity, $\Gamma(x) =
\Gamma(Q,\pfracb{Q}{x})$ is a flux function, $S(x,t) = S(Q,x,t)$ is a
source function and $V' = V'(x)$ is a given function. To descritize
this equation consider a finite-volume grid in which a cell is defined
as $C_i \equiv [x_i, x_{i+1}]$, with $i=1,\ldots,N$ and the unknown
quantities are located at cell-centers $Q_i^n = Q(x_{i+1/2},t_n)$,
fluxes are located at cell-edges $\Gamma_i = \Gamma(x_i)$ and sources
are located at cell-centers $S_i = S(x_{i+1/2},t)$. Here, $x_{i+1/2}
\equiv (x_i+x_{i+1})/2$ and $\Delta x_i \equiv (x_{i+1}-x_i)$. Using a
second order central difference for the spatial operator and
first-order implicit difference for the time derivate we get an update
formula
\begin{align}
  Q_i^{n+1} = Q^n_i - \frac{\Delta t}{V'(x_i) \Delta x_i}
  \left (
    V'(x_{i+1/2}) F_{i+1} - V'(x_{i-1/2}) F_i
  \right)
  +
  \Delta t S_i \equiv D(F_{i+1}, F_{i}) \label{eqn:update-form}
\end{align}
where
\begin{align}
  F_i = H(Q_i^{n+1}, Q_{i-1}^{n+1}) \label{eqn:flux-func}
\end{align}
is the numerical flux function defined such that $H(Q,Q) =
\Gamma(Q,\pfracb{Q}{x})$.

A standard implicit method would solve the system of equations arising
from inserting the definition of the numerical flux into the update
formula, resulting a system of non-linear algebraic equations for the
$N$ unknowns $Q_i^{n+1}$. However, in this note we consider the
possibility of instread solving the system of coupled $2N$ algebraic
equations (dropping the superscripts)
\begin{align}
  Q_i - D(F_{i+1}, F_i) &= 0  \label{eqn:q-eqn} \\
  F_i - H(Q_i, Q_{i-1}) &= 0. \label{eqn:f-eqn}
\end{align}
for the $2N$ unknowns $[Q_1, \ldots, Q_N, F_1, \ldots F_N
]^T$. Letting $\mvec{V} \equiv [\mvec{Q}, \mvec{F}]^T$, where
$\mvec{Q} \equiv [Q_1, \ldots, Q_N]^T$ and $\mvec{F} \equiv [F_1,
\ldots, F_N]^T$ we can write the problem schematically as finding the
roots of the non-linear system of algebraic equations
\begin{align}
  \mvec{G}(\mvec{V}) = \mvec{0} \label{eqn:g-eqn}
\end{align}
where $G_i \equiv Q_i - D(F_{i+1}, F_i)$, and $G_{i+N} \equiv F_i -
F(Q_i, Q_{i-1})$ for $i=1,\ldots,N$. In the following also let
$\mvec{D} \equiv [D_1,\ldots,D_N]^T$ and $\gvec{H} \equiv
[H_1,\ldots,H_N]^T$.

To use a Newton method for solving the non-linear system we need to
compute, at least approximately, the inverse of the Jacobian matrix
$\mvec{J} \equiv \mvec{G}'(\mvec{V})$. The Jacobian itself can be
computed using \eqr{\ref{eqn:g-eqn}} and Eqns.\thinspace
(\ref{eqn:q-eqn}) and (\ref{eqn:f-eqn}) as
\begin{align}
  \mvec{J} =
  \left[
    \begin{array}{cc}
      \mvec{I} & -\pfracb{\mvec{D}}{\mvec{F}} \\
      -\pfracb{\mvec{H}}{\mvec{Q}} & \mvec{I}
    \end{array}
  \right]
\end{align}
Here $\mvec{I}$ is a $N\times N$ unit matrix. Also, it is clear from
Eqns.\thinspace (\ref{eqn:update-form}) and (\ref{eqn:flux-func}),
$\mvec{J}_{12} \equiv -\pfracb{\mvec{D}}{\mvec{F}}$ and $
\mvec{J}_{21} \equiv -\pfracb{\mvec{H}}{\mvec{Q}}$ are bi-diagonal
matrices, the former with a super-diagonal and the latter with a
sub-diagonal. Further, due to the assumed functional form of
$\mvec{S}$, the matrix $\mvec{J}_{12}$ is linear, i.e. does not depend
on either $\mvec{Q}$ or $\mvec{F}$.

Let $\mvec{K} = \mvec{J}^{-1}$, and
\begin{align}
  \mvec{K} = 
  \left[
    \begin{array}{cc}
      \mvec{K}_{11} & \mvec{K}_{12} \\
      \mvec{K}_{21} & \mvec{K}_{22}
    \end{array}
  \right]
\end{align}
Then, using $\mvec{J}\mvec{K} = \mvec{I}$, we can show that
\begin{align}
  \mvec{K}_{11} &= (\mvec{I} - \mvec{J}_{12}\mvec{J}_{21})^{-1} \\
  \mvec{K}_{22} &= (\mvec{I} - \mvec{J}_{21}\mvec{J}_{12})^{-1} \\
  \mvec{K}_{12} &= -\mvec{J}_{12} \mvec{K}_{22} \\
  \mvec{K}_{21} &= -\mvec{J}_{21} \mvec{K}_{11}.
\end{align}
As $\mvec{J}_{12}$ and $\mvec{J}_{21}$ are bidiagonal matrices one
with a sub-diagonal and the other with a super-diagonal, the matrices
$\mvec{I} - \mvec{J}_{12}\mvec{J}_{21}$ and $\mvec{I} -
\mvec{J}_{21}\mvec{J}_{12}$ are tri-diagonal. Hence, to compute the
Newton iteration increments in a naive brute-force algorithm requires
two matrix-matrix multiplications of bi-diagonal matrices, two
tri-diagonal inversions and two matrix-vector products with a
bi-diagonal matrix.

\subsection{Boundary conditions}

In typical transport problems the boundary conditions are $\Gamma(0) =
0$ and $Q(x_R,t) = Q_0(t)$, where $Q_0(t)$ is a specified function and
$0<x<x_R$ is the domain. A possible discretization is to select a grid
such that the $N$th cell-center lies at $x_R$. i.e.  for a uniform
grid we have $\Delta x (N-1) + \Delta x/2 = x_R$ which implies that
$\Delta x = 2x_R/(2N-1)$. Then, to impose the boundary conditions we
can simply set $H_1 = 0$ and $D_N = Q_0(x_R,t)$, thus completing the
problem description.

\subsection{Extension to a system of transport equations}

For most applications the transport of more than one quantity needs to
be evolved. In this case the system of equations is generally coupled,
i.e. the fluxes of one quantity depend on the values and gradients of
all the other quantities. In this case the blocks of the $\mvec{J}$
matrix become block bi-diagonal and the blocks of $\mvec{K}$ become
inverses of block tri-diagonal matrices. In general, each $M\times M$
sub-block, where $M$ is the number of transport equations being
solved, of $\pfracb{\mvec{H}}{\mvec{Q}}$ is dense. However, each
$M\times M$ sub-block of $\pfracb{\mvec{D}}{\mvec{Q}}$ is diagonal as
the update formulas for each quantity are uncoupled.
